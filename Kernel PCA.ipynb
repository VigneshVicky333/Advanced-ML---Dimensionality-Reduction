{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5f14af-b8e6-4d37-8fca-e7a5feca1e56",
   "metadata": {},
   "source": [
    "## Concept of Kernel PCA:\n",
    "\n",
    "Kernel PCA (Principal Component Analysis) is an extension of the regular PCA (Principal Component Analysis) method that allows the data to be mapped into a higher-dimensional feature space using a kernel function, making it possible to capture non-linear patterns in the data. Kernel PCA is particularly useful when dealing with non-linear relationships between features.\n",
    "\n",
    "In contrast to standard PCA, which relies on linear projections, Kernel PCA leverages different kernel functions to implicitly map data into a higher-dimensional space, where linear separability might be easier to achieve.\n",
    "\n",
    "### Steps to Apply Kernel PCA:\n",
    "\n",
    "#### Preprocess Data:\n",
    "- Load the dataset.\n",
    "- Handle categorical variables using label encoding.\n",
    "- Scale the features using standardization.\n",
    "\n",
    "#### Apply Kernel PCA:\n",
    "- Choose an appropriate kernel (e.g., RBF, polynomial, etc.).\n",
    "- Apply Kernel PCA for dimensionality reduction.\n",
    "\n",
    "#### Train Multiple Classifiers:\n",
    "- Use various classifiers (e.g., Logistic Regression, SVM, KNN, etc.) on the reduced data.\n",
    "\n",
    "#### Evaluate Performance:\n",
    "- Evaluate the accuracy of each classifier and display the results in a tabular format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ca0b5-b339-49a4-9ce6-23ac664e1941",
   "metadata": {},
   "source": [
    "#### Steps and Code Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0cc7ddb-6167-4983-b3d8-b0ee06b9946e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance with Kernel PCA:\n",
      "            Logistic    SVMl  SVMnl    KNN  Navie  Decision  Random\n",
      "Kernel PCA     0.975  0.9625  0.975  0.975  0.975    0.9875   0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "dataset = pd.read_csv('prep.csv')\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "labelencoder = LabelEncoder()\n",
    "y = dataset.iloc[:, -1].values  # Target variable\n",
    "X = dataset.iloc[:, :-1].values  # Features\n",
    "\n",
    "# Encode categorical variables if needed\n",
    "for i in range(X.shape[1]):\n",
    "    if X[:, i].dtype == 'object':  # Check for categorical columns\n",
    "        X[:, i] = labelencoder.fit_transform(X[:, i])\n",
    "\n",
    "# Step 3: Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # Scale the features\n",
    "\n",
    "# Step 4: Apply Kernel PCA for non-linear dimensionality reduction\n",
    "kernel_pca = KernelPCA(n_components=2, kernel='rbf')  # You can choose other kernels like 'poly', 'sigmoid', etc.\n",
    "X_kpca = kernel_pca.fit_transform(X_scaled)\n",
    "\n",
    "# Step 5: Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_kpca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Initialize classifiers\n",
    "models = {\n",
    "    'Logistic': LogisticRegression(),\n",
    "    'SVMl': SVC(kernel='linear'),\n",
    "    'SVMnl': SVC(kernel='rbf'),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Navie': GaussianNB(),\n",
    "    'Decision': DecisionTreeClassifier(),\n",
    "    'Random': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Step 7: Evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "\n",
    "# Step 8: Convert results to a DataFrame and print\n",
    "results_df = pd.DataFrame([results], index=['Kernel PCA'])\n",
    "print(\"Model Performance with Kernel PCA:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2349f-3db1-40a2-9913-de6280d10f92",
   "metadata": {},
   "source": [
    "## Model Performance with Kernel PCA:\n",
    "\n",
    "| Model        | Logistic | SVM (Linear) | SVM (Non-linear) | KNN    | Naive Bayes | Decision Tree | Random Forest |\n",
    "|--------------|----------|--------------|------------------|--------|-------------|---------------|---------------|\n",
    "| **Kernel PCA** | 0.975    | 0.9625       | 0.975            | 0.975  | 0.975       | 0.9875        | 0.975         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de562d-db6b-48ed-a58f-eb5e9ba55988",
   "metadata": {},
   "source": [
    "By using this code, you should be able to evaluate the performance of different classifiers on the data after applying Kernel PCA and display the results in a table format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4f071-615a-48bf-a2ab-93c62f9eba63",
   "metadata": {},
   "source": [
    "## Explanation of the Code:\n",
    "\n",
    "### Preprocessing:\n",
    "\n",
    "- **The LabelEncoder** is used to convert categorical features into numerical values.\n",
    "- **Feature scaling** is performed using StandardScaler to standardize the features, which is important when using kernel methods.\n",
    "\n",
    "### Kernel PCA:\n",
    "\n",
    "- **KernelPCA(n_components=2, kernel='rbf')** is used for non-linear dimensionality reduction. The RBF kernel is used here, but you can also experiment with other kernels such as poly, sigmoid, etc. This maps the data to a higher-dimensional space using the chosen kernel and then performs PCA on that transformed space.\n",
    "\n",
    "### Model Training:\n",
    "\n",
    "- **Multiple classifiers** are trained using the reduced dataset (`X_kpca`), which is the result of the kernel PCA transformation.\n",
    "\n",
    "### Evaluation:\n",
    "\n",
    "- **Each classifierâ€™s performance** is evaluated using accuracy. The results are stored in the `results` dictionary, which is then converted into a pandas DataFrame for easy display.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128e5db-7f7d-436c-aa61-9c8225bad172",
   "metadata": {},
   "source": [
    "## Key Points:\n",
    "\n",
    "### Kernel Choice:\n",
    "- Kernel PCA uses a kernel function to map the data into a higher-dimensional feature space. The most common kernel is the RBF kernel, which can capture non-linear relationships. You can also experiment with other kernels such as polynomial or sigmoid.\n",
    "\n",
    "### Dimensionality Reduction:\n",
    "- The number of components (`n_components`) should be chosen based on your dataset and the number of features you want to reduce to. For example, in this case, we reduce the data to 2 components.\n",
    "\n",
    "### Model Performance:\n",
    "- After applying Kernel PCA, you can train different classifiers on the transformed data and evaluate their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee19ca-35b3-472e-8460-d81e5dc0a16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
